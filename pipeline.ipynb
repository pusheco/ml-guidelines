{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_profiling\n",
    "import category_encoders\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, GridSearchCV, cross_validate\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Read data\n",
    "- read from csv, json or database into dataframes\n",
    "- create pandas profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv()\n",
    "df2 = pd.read_pickle()\n",
    "df3 = pd.read_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check data profiles and dicide about categoricals, missing values, ...\n",
    "df1.describe()\n",
    "profile = df1.profile_report(title='df1 report')\n",
    "profile.to_file(output_file=\"df1_profile.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Clean data\n",
    "For each dataframe:\n",
    "- handle categoricals\n",
    "- remove unwanted rows \n",
    "- remove unwanted columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove unwanted categories (seperately do it for each categorical columns)\n",
    "df1.loc[~df1.col1.isin(['a','b','c']),'col1'] = 'others'\n",
    "\n",
    "# convert to pandas categorical first, and then get its codes\n",
    "categorical_columns = ['col1','col2']\n",
    "for col in categorical_columns:\n",
    "    df1[col] = fd1[col].astype('category').cat.codes\n",
    "\n",
    "# use any encoding methods (e.g. one-hot encoding or hashing) if needed\n",
    "selected_columns =  ['col1']\n",
    "ohe = category_encoders.OneHotEncoder(cols=selected_columns)\n",
    "df1 = ohe.fit_transform(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Feature engineering\n",
    "- merge dataframes &rarr; `data`\n",
    "- handle missing values\n",
    "- add extra features &rarr; `features`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge (join)\n",
    "data = pd.merge(df1, df2, on='col1', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows or columns with lots of missing values \n",
    "# impute missing values with mean or something else\n",
    "selected_columns = ['col1', 'col2']\n",
    "for col in selected_columns:\n",
    "    data.col.fillna(data.col.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature engineering\n",
    "features = data.copy()\n",
    "features['new_col'] = features.col1 / features.col2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Split train-test\n",
    "- output: `train` `test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split\n",
    "train, test = train_test_split(features, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Train models\n",
    "For each model define a new method with the following style (pay attention to normalization):\n",
    "```python\n",
    "# psuedocode\n",
    "def train_pipeline(train, model, scaler):\n",
    "    train_features = [...]\n",
    "    label = ...\n",
    "    xtrain = train[train_features]\n",
    "    ytrain = train[label]\n",
    "    pipeline = Pipeline([('transformer', scalar), ('estimator', model)])\n",
    "    print('cv score: ', cross_val_score(pipeline, xtrain, ytrain, cv=5).mean())\n",
    "    train_pred_cv = cross_val_predict(model, xtrain, ytrain, cv=5)\n",
    "    model.fit(xtrain, ytrain)\n",
    "    return model, train_pred_cv\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1, train_predictions_1 = train_pipeline(train, model=RandomForrestRegressor(), scaler=RobustScaler())\n",
    "model2, train_predictions_2 = train_pipeline(train, model=KNNRegressor(), scaler=StandardScaler())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Stack models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_features = pd.DataFrame(\n",
    "    {'model1': train_predictions_1, 'model2': train_predictions_2, label: train.label}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stacked_model, train_pred_stack = train_pipline(stacked_features, LinearRegression(), scaler=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 Evaluate on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = stacked_model.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(ytest, test_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
